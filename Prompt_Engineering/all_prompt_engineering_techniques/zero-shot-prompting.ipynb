{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Zero-Shot Prompting Tutorial\n",
        "\n",
        "## Overview\n",
        "\n",
        "This tutorial provides a comprehensive introduction to zero-shot prompting, a powerful technique in prompt engineering that allows language models to perform tasks without specific examples or prior training. We'll explore how to design effective zero-shot prompts and implement strategies using OpenAI's GPT models and the LangChain library.\n",
        "\n",
        "## Motivation\n",
        "\n",
        "Zero-shot prompting is crucial in modern AI applications as it enables language models to generalize to new tasks without the need for task-specific training data or fine-tuning. This capability significantly enhances the flexibility and applicability of AI systems, allowing them to adapt to a wide range of scenarios and user needs with minimal setup.\n",
        "\n",
        "## Key Components\n",
        "\n",
        "1. **Understanding Zero-Shot Learning**: An introduction to the concept and its importance in AI.\n",
        "2. **Prompt Design Principles**: Techniques for crafting effective zero-shot prompts.\n",
        "3. **Task Framing**: Methods to frame various tasks for zero-shot performance.\n",
        "4. **OpenAI Integration**: Using OpenAI's GPT models for zero-shot tasks.\n",
        "5. **LangChain Implementation**: Leveraging LangChain for structured zero-shot prompting.\n",
        "\n",
        "## Method Details\n",
        "\n",
        "The tutorial will cover several methods for implementing zero-shot prompting:\n",
        "\n",
        "1. **Direct Task Specification**: Crafting prompts that clearly define the task without examples.\n",
        "2. **Role-Based Prompting**: Assigning specific roles to the AI to guide its responses.\n",
        "3. **Format Specification**: Providing output format guidelines in the prompt.\n",
        "4. **Multi-step Reasoning**: Breaking down complex tasks into simpler zero-shot steps.\n",
        "5. **Comparative Analysis**: Evaluating different zero-shot prompt structures for the same task.\n",
        "\n",
        "Throughout the tutorial, we'll use Python code with OpenAI and LangChain to demonstrate these techniques practically.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "By the end of this tutorial, learners will have gained:\n",
        "\n",
        "1. A solid understanding of zero-shot prompting and its applications.\n",
        "2. Practical skills in designing effective zero-shot prompts for various tasks.\n",
        "3. Experience in implementing zero-shot techniques using OpenAI and LangChain.\n",
        "4. Insights into the strengths and limitations of zero-shot approaches.\n",
        "5. A foundation for further exploration and innovation in prompt engineering.\n",
        "\n",
        "This knowledge will empower learners to leverage AI models more effectively across a wide range of applications, enhancing their ability to solve novel problems and create more flexible AI systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Let's start by importing the necessary libraries and setting up our environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Ollama on MAC (port 12434).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Set up OpenAI API key\n",
        "# os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
        "# Initialize the language model\n",
        "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "from select_llm import get_llm, get_supported_ollama_models\n",
        "ollama_model = \"mistral:latest\"  # or None for OpenAI\n",
        "# ollama_model = \"llama3.2:1b\"  # or None for OpenAI\n",
        "# ollama_model = \"tinyllama:latest\"  # or None for OpenAI\n",
        "# ollama_model = \"deepseek-r1:7b\"\n",
        "llm = get_llm(ollama_model) #,force_port=12434)\n",
        "if llm is None:\n",
        "    models = get_supported_ollama_models()\n",
        "    print(\"Available Ollama models:\", models)\n",
        "\n",
        "def create_chain(prompt_template, print_prompt=False):\n",
        "    \"\"\"\n",
        "    Create a LangChain chain with the given prompt template.\n",
        "    \n",
        "    Args:\n",
        "        prompt_template (str): The prompt template string.\n",
        "        print_prompt (bool): If True, print the formatted prompt when invoke() is called.\n",
        "    \n",
        "    Returns:\n",
        "        LangChain LCEL chain (prompt | llm).\n",
        "    \"\"\"\n",
        "    prompt = PromptTemplate.from_template(prompt_template)\n",
        "    chain = prompt | llm\n",
        "    if print_prompt:\n",
        "        class ChainWithPrintPrompt:\n",
        "            def invoke(self, inputs, *args, **kwargs):\n",
        "                print(\"--- Prompt sent to model ---\")\n",
        "                print(prompt.format(**inputs))\n",
        "                print(\"---\")\n",
        "                return chain.invoke(inputs, *args, **kwargs)\n",
        "        return ChainWithPrintPrompt()\n",
        "    return chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Direct Task Specification\n",
        "\n",
        "In this section, we'll explore how to craft prompts that clearly define the task without providing examples. This is the essence of zero-shot prompting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "direct_task_prompt = \"\"\"Classify the sentiment of the following text as positive, negative, or neutral.\n",
        "Do not explain your reasoning, just provide the classification.\n",
        "\n",
        "Text: {text}\n",
        "\n",
        "Sentiment:\"\"\"\n",
        "\n",
        "direct_task_chain = create_chain(direct_task_prompt)\n",
        "\n",
        "# Test the direct task specification\n",
        "texts = [\n",
        "    \"I absolutely loved the movie! The acting was superb.\",\n",
        "    \"The weather today is quite typical for this time of year.\",\n",
        "    \"I'm disappointed with the service I received at the restaurant.\"\n",
        "]\n",
        "\n",
        "for text in texts:\n",
        "    result = direct_task_chain.invoke({\"text\": text}).content\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Sentiment: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Format Specification\n",
        "\n",
        "Providing output format guidelines in the prompt can help structure the AI's response in a zero-shot scenario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Headline: A New Earth-Like Exoplanet Discovered in Habitable Zone - Kepler-452b Could be Our Cosmic Twin!\n",
            "\n",
            "Lead: Astronomers have announced the discovery of a new exoplanet, Kepler-452b, located within the habitable zone of its star and displaying characteristics remarkably similar to Earth. This exciting find offers tantalizing possibilities for future study and could potentially harbor life beyond our own planet.\n",
            "\n",
            "Body:\n",
            "\n",
            "1. Location and Orbit: Kepler-452b resides in a solar system approximately 1,400 light years from Earth, orbiting its star within the habitable zone - the area where liquid water may exist on the planet's surface. This position suggests that conditions are suitable for life as we know it.\n",
            "\n",
            "2. Size and Temperature: The exoplanet has a radius that is 60% larger than Earth, leading scientists to believe it may have a dense atmosphere similar to that of Venus. However, recent data indicates that its surface temperature could be relatively mild, with an average of 20 degrees Celsius (68 degrees Fahrenheit).\n",
            "\n",
            "3. Star System: The host star, Kepler-452, is older and larger than our sun, providing a longer history for the possible development of life on the exoplanet. Additionally, the star system lies within the constellation Cygnus, making it visible from Earth with the naked eye during the northern hemisphere's summer months.\n",
            "\n",
            "Conclusion:\n",
            "The discovery of Kepler-452b marks an important milestone in our ongoing search for habitable planets and life beyond our solar system. Future research will focus on determining more precise details about this tantalizing new world, such as its atmospheric composition and the presence of liquid water or other essential components for life. As we continue to explore and learn, we are one step closer to answering the age-old question: Are we alone in the universe?\n"
          ]
        }
      ],
      "source": [
        "format_spec_prompt = \"\"\"Generate a short news article about {topic}. \n",
        "Structure your response in the following format:\n",
        "\n",
        "Headline: [A catchy headline for the article]\n",
        "\n",
        "Lead: [A brief introductory paragraph summarizing the key points]\n",
        "\n",
        "Body: [2-3 short paragraphs providing more details]\n",
        "\n",
        "Conclusion: [A concluding sentence or call to action]\n",
        "\n",
        "IMPORTANT: {important_note}\n",
        "\"\"\"\n",
        "\n",
        "format_spec_chain = create_chain(format_spec_prompt)\n",
        "\n",
        "# Test the format specification prompting\n",
        "topic = \"The discovery of a new earth-like exoplanet\"\n",
        "note = \"Always use these exact section labels on their own lines: Headline:, Lead:, Body:, Conclusion:. Include 'Body:' immediately before the 2-3 detail paragraphs.\"\n",
        "result = format_spec_chain.invoke({\"topic\": topic, \"important_note\": note}).content\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Multi-step Reasoning\n",
        "\n",
        "For complex tasks, we can break them down into simpler zero-shot steps. This approach can improve the overall performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "multi_step_prompt = \"\"\"Analyze the following text for its main argument, supporting evidence, and potential counterarguments. \n",
        "Provide your analysis in the following steps:\n",
        "\n",
        "1. Main Argument: Identify and state the primary claim or thesis.\n",
        "2. Supporting Evidence: List the key points or evidence used to support the main argument.\n",
        "3. Potential Counterarguments: Suggest possible objections or alternative viewpoints to the main argument.\n",
        "\n",
        "Text: {text}\n",
        "\n",
        "Analysis:\"\"\"\n",
        "\n",
        "multi_step_chain = create_chain(multi_step_prompt,print_prompt=True)\n",
        "\n",
        "# Test the multi-step reasoning approach\n",
        "text = \"\"\"While electric vehicles are often touted as a solution to climate change, their environmental impact is not as straightforward as it seems. \n",
        "The production of batteries for electric cars requires significant mining operations, which can lead to habitat destruction and water pollution. \n",
        "Moreover, if the electricity used to charge these vehicles comes from fossil fuel sources, the overall carbon footprint may not be significantly reduced. \n",
        "However, as renewable energy sources become more prevalent and battery technology improves, electric vehicles could indeed play a crucial role in combating climate change.\"\"\"\n",
        "\n",
        "result = multi_step_chain.invoke({\"text\": text}).content\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Comparative Analysis\n",
        "\n",
        "Let's compare different zero-shot prompt structures for the same task to evaluate their effectiveness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compare_prompts(task, prompt_templates, print_prompt=False):\n",
        "    \"\"\"\n",
        "    Compare different prompt templates for the same task.\n",
        "    \n",
        "    Args:\n",
        "        task (str): The task description or input.\n",
        "        prompt_templates (dict): A dictionary of prompt templates with their names as keys.\n",
        "        print_prompt (bool): If True, print the formatted prompt for each template before the result.\n",
        "    \"\"\"\n",
        "    print(f\"Task: {task}\\n\")\n",
        "    for name, template in prompt_templates.items():\n",
        "        chain = create_chain(template, print_prompt=print_prompt)\n",
        "        result = chain.invoke({\"task\": task}).content\n",
        "        print(f\"{name} Prompt Result:\")\n",
        "        print(result)\n",
        "        print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "task = \"Explain concisely the concept of blockchain technology\"\n",
        "\n",
        "prompt_templates = {\n",
        "    \"Basic\": \"Explain {task}.\",\n",
        "    \"Structured\": \"\"\"Explain {task} by addressing the following points:\n",
        "1. Definition\n",
        "2. Key features\n",
        "3. Real-world applications\n",
        "4. Potential impact on industries\"\"\"\n",
        "}\n",
        "\n",
        "compare_prompts(task, prompt_templates,print_prompt=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
