{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chain of Thought (CoT) Prompting Tutorial\n",
        "\n",
        "## Overview\n",
        "\n",
        "This tutorial introduces Chain of Thought (CoT) prompting, a powerful technique in prompt engineering that encourages AI models to break down complex problems into step-by-step reasoning processes. We'll explore how to implement CoT prompting using OpenAI's GPT models and the LangChain library.\n",
        "\n",
        "## Motivation\n",
        "\n",
        "As AI language models become more advanced, there's an increasing need to guide them towards producing more transparent, logical, and verifiable outputs. CoT prompting addresses this need by encouraging models to show their work, much like how humans approach complex problem-solving tasks. This technique not only improves the accuracy of AI responses but also makes them more interpretable and trustworthy.\n",
        "\n",
        "## Key Components\n",
        "\n",
        "1. **Basic CoT Prompting**: Introduction to the concept and simple implementation.\n",
        "2. **Advanced CoT Techniques**: Exploring more sophisticated CoT approaches.\n",
        "3. **Comparative Analysis**: Examining the differences between standard and CoT prompting.\n",
        "4. **Problem-Solving Applications**: Applying CoT to various complex tasks.\n",
        "\n",
        "## Method Details\n",
        "\n",
        "The tutorial will guide learners through the following methods:\n",
        "\n",
        "1. **Setting up the environment**: We'll start by importing necessary libraries and setting up the OpenAI API.\n",
        "\n",
        "2. **Basic CoT Implementation**: We'll create simple CoT prompts and compare their outputs to standard prompts.\n",
        "\n",
        "3. **Advanced CoT Techniques**: We'll explore more complex CoT strategies, including multi-step reasoning and self-consistency checks.\n",
        "\n",
        "4. **Practical Applications**: We'll apply CoT prompting to various problem-solving scenarios, such as mathematical word problems and logical reasoning tasks.\n",
        "\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "By the end of this tutorial, learners will have a solid understanding of Chain of Thought prompting and its applications. They will be equipped with practical skills to implement CoT techniques in various scenarios, improving the quality and interpretability of AI-generated responses. This knowledge will be valuable for anyone working with large language models, from developers and researchers to business analysts and decision-makers relying on AI-powered insights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Let's start by importing the necessary libraries and setting up our environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Set up OpenAI API key\n",
        "# os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
        "# Initialize the language model\n",
        "# llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
        "\n",
        "from select_llm import get_llm, get_supported_ollama_models\n",
        "ollama_model = \"mistral:latest\"  # or None for OpenAI\n",
        "ollama_model2 = \"llama3.2:1b\"  # or None for OpenAI\n",
        "# ollama_model = \"tinyllama:latest\"  # or None for OpenAI\n",
        "#ollama_model = \"deepseek-r1:7b\"\n",
        "llm = get_llm(ollama_model, temperature=0) #,force_port=12434)\n",
        "if llm is None:\n",
        "    models = get_supported_ollama_models()\n",
        "    print(\"Available Ollama models:\", models)\n",
        "llm2 = get_llm(ollama_model2, temperature=0) #,force_port=12434)\n",
        "if llm2 is None:\n",
        "    models = get_supported_ollama_models()\n",
        "    print(\"Available Ollama models:\", models)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic Chain of Thought Prompting\n",
        "\n",
        "Let's start with a simple example to demonstrate the difference between a standard prompt and a Chain of Thought prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard prompt\n",
        "standard_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"Answer the following question concisely: {question}.\"\n",
        ")\n",
        "\n",
        "# Chain of Thought prompt\n",
        "cot_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"Answer the following question step by step concisely: {question}\"\n",
        ")\n",
        "\n",
        "# Create chains\n",
        "standard_chain = standard_prompt | llm\n",
        "cot_chain = cot_prompt | llm\n",
        "\n",
        "# Example question\n",
        "# question = \"If a train travels 120 km in 2 hours, what is its average speed in km/h?\"\n",
        "#question = \"what is the sum of all numbers from 1 to 100 when the first number is multiplied by 1, the second by 2, the third by 3 and so on (1+2*2+3*3+...)?\"\n",
        "question = \"what is the sum of all numbers according to this sequence: 1*1+2*2+3*3+...+100*100)?\"\n",
        "\n",
        "# Get responses\n",
        "standard_response = standard_chain.invoke(question).content\n",
        "print(\"Standard Response:\")\n",
        "print(standard_response)\n",
        "\n",
        "cot_response = cot_chain.invoke(question).content\n",
        "print(\"\\nChain of Thought Response:\")\n",
        "print(cot_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advanced Chain of Thought Techniques\n",
        "\n",
        "Now, let's explore a more advanced CoT technique that encourages multi-step reasoning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "advanced_cot_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"\"\"Solve the following problem step by step. For each step:\n",
        "1. State what you're going to calculate\n",
        "2. Write the formula you'll use (if applicable)\n",
        "3. Perform the calculation\n",
        "4. Explain the result\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Solution:\"\"\"\n",
        ")\n",
        "\n",
        "advanced_cot_chain = advanced_cot_prompt | llm\n",
        "\n",
        "complex_question = \"A car travels 150 km at 60 km/h, then another 100 km at 50 km/h. What is the average speed for the entire journey?\"\n",
        "\n",
        "advanced_cot_response = advanced_cot_chain.invoke(complex_question).content\n",
        "print(advanced_cot_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparative Analysis\n",
        "\n",
        "Let's compare the effectiveness of standard prompting vs. CoT prompting on a more challenging problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "challenging_question = \"\"\"\n",
        "A cylindrical water tank with a radius of 1.5 meters and a height of 4 meters is 2/3 full. \n",
        "If water is being added at a rate of 10 liters per minute, how long will it take for the tank to overflow? \n",
        "Give your answer in hours and minutes, rounded to the nearest minute. \n",
        "(Use 3.14159 for π and 1000 liters = 1 cubic meter)\"\"\"\n",
        "\n",
        "standard_response = standard_chain.invoke(challenging_question).content\n",
        "print(\"Standard Response:\")\n",
        "print(standard_response)\n",
        "\n",
        "cot_response = advanced_cot_chain.invoke(challenging_question).content\n",
        "print(\"\\nChain of Thought Response:\")\n",
        "print(cot_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problem-Solving Applications\n",
        "\n",
        "Now, let's apply CoT prompting to a more complex logical reasoning task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#llm = ChatOpenAI(model_name=\"gpt-4o\")\n",
        "\n",
        "logical_reasoning_prompt = PromptTemplate(\n",
        "    input_variables=[\"scenario\"],\n",
        "    template=\"\"\"Analyze the following logical puzzle thoroughly. Follow these steps in your analysis:\n",
        "\n",
        "List the Facts:\n",
        "\n",
        "Summarize all the given information and statements clearly.\n",
        "Identify all the characters or elements involved.\n",
        "Identify Possible Roles or Conditions:\n",
        "\n",
        "Determine all possible roles, behaviors, or states applicable to the characters or elements (e.g., truth-teller, liar, alternator).\n",
        "Note the Constraints:\n",
        "\n",
        "Outline any rules, constraints, or relationships specified in the puzzle.\n",
        "Generate Possible Scenarios:\n",
        "\n",
        "Systematically consider all possible combinations of roles or conditions for the characters or elements.\n",
        "Ensure that all permutations are accounted for.\n",
        "Test Each Scenario:\n",
        "\n",
        "For each possible scenario:\n",
        "Assume the roles or conditions you've assigned.\n",
        "Analyze each statement based on these assumptions.\n",
        "Check for consistency or contradictions within the scenario.\n",
        "Eliminate Inconsistent Scenarios:\n",
        "IMPORTANT: Evaluate and think thoroughly about ALL scenarios, not just a few!\n",
        "NOTE: Include the given details of each character or element in the scenario and use them in the analysis.\n",
        "Discard any scenarios that lead to contradictions or violate the constraints.\n",
        "Keep track of the reasoning for eliminating each scenario.\n",
        "Conclude the Solution:\n",
        "\n",
        "Identify the scenario(s) that remain consistent after testing.\n",
        "Each scenario shall contain the character or element and its role or condition.\n",
        "Summarize the findings.\n",
        "Provide a Clear Answer:\n",
        "\n",
        "State definitively the role or condition of each character or element.\n",
        "Explain why this is the only possible solution based on your analysis.\n",
        "Scenario:\n",
        "\n",
        "{scenario}\n",
        "\n",
        "Analysis:\"\"\")\n",
        "\n",
        "logical_reasoning_chain = logical_reasoning_prompt | llm\n",
        "\n",
        "logical_puzzle = \"\"\"In a room, there are three people: Amy, Bob, and Charlie. \n",
        "One of them always tells the truth, one always lies, and one alternates between truth and lies. \n",
        "Amy says, 'Bob is a liar.' \n",
        "Bob says, 'Charlie alternates between truth and lies.' \n",
        "Charlie says, 'Amy and I are both liars.' \n",
        "Determine the nature (truth-teller, liar, or alternator) of each person.\"\"\"\n",
        "\n",
        "logical_reasoning_response = logical_reasoning_chain.invoke(logical_puzzle).content\n",
        "print(logical_reasoning_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " List the Facts:\n",
            "- There are three people in the room: Amy, Bob, and Charlie.\n",
            "- One is a truth-teller, one is a liar, and one alternates between truth and lies.\n",
            "- Amy says that Bob is a liar.\n",
            "- Bob says that Charlie alternates between truth and lies.\n",
            "- Charlie says that both Amy and he are liars.\n",
            "\n",
            "Identify Possible Roles or Conditions:\n",
            "- Truth-teller (TT): always tells the truth.\n",
            "- Liar (L): always lies.\n",
            "- Alternator (A): alternates between telling the truth and lying.\n",
            "\n",
            "Note the Constraints:\n",
            "- There is exactly one of each role in the room.\n",
            "- Amy, Bob, and Charlie are distinct individuals.\n",
            "\n",
            "Generate Possible Scenarios:\n",
            "1. TT-L-A\n",
            "2. L-TT-A\n",
            "3. A-TT-L\n",
            "4. TT-A-L\n",
            "5. L-A-TT\n",
            "6. A-L-TT\n",
            "7. A-TT-A (This scenario is invalid because it assigns the same role to two characters, violating the constraint that there is exactly one of each role.)\n",
            "\n",
            "Test Each Scenario:\n",
            "1. TT-L-A:\n",
            "   - Amy (TT): If Amy is a truth-teller, then her statement about Bob being a liar must be true. This means Bob is indeed a liar.\n",
            "   - Bob (L): Since Bob is a liar, his statement about Charlie alternating between truth and lies cannot be trusted. However, it doesn't contradict the scenario since we don't know whether Charlie actually alternates or not.\n",
            "   - Charlie (A): Since Amy told the truth about Bob being a liar, and Bob lied about Charlie, it is possible that Charlie alternates between truth and lies in this scenario.\n",
            "2. L-TT-A:\n",
            "   - Amy (L): Since Amy is a liar, her statement about Bob being a liar contradicts the fact that Bob is a truth-teller. This scenario can be eliminated.\n",
            "   - Bob (TT): If Bob is a truth-teller, then his statement about Charlie alternating between truth and lies must be true. However, it doesn't contradict the scenario since we don't know whether Charlie actually alternates or not.\n",
            "   - Charlie (A): Since Bob told the truth about Charlie alternating between truth and lies, and Amy lied about Bob being a liar, it is possible that Charlie alternates between truth and lies in this scenario.\n",
            "3. A-TT-L:\n",
            "   - Amy (A): Since Amy's statement about Bob being a liar contradicts the fact that Bob is a truth-teller, it must be a lie. This means Bob is not a liar, which implies he is either a truth-teller or an alternator.\n",
            "   - Bob (TT): If Bob is a truth-teller, then his statement about Charlie alternating between truth and lies cannot be trusted. However, it doesn't contradict the scenario since we don't know whether Charlie actually alternates or not.\n",
            "   - Charlie (L): Since Amy lied about Bob being a liar, and her lie implies that Bob is not a liar, it follows that Charlie must be the liar in this scenario.\n",
            "4. TT-A-L:\n",
            "   - Amy (TT): If Amy is a truth-teller, then her statement about Bob being a liar must be true. This means Bob is indeed a liar.\n",
            "   - Bob (L): Since Bob is a liar, his statement about Charlie alternating between truth and lies cannot be trusted. However, it doesn't contradict the scenario since we don't know whether Charlie actually alternates or not.\n",
            "   - Charlie (A): Since Amy told the truth about Bob being a liar, and Bob lied about Charlie, it is possible that Charlie alternates between truth and lies in this scenario.\n",
            "5. L-A-TT:\n",
            "   - Amy (L): Since Amy is a liar, her statement about Bob being a liar contradicts the fact that Bob is a truth-teller. This scenario can be eliminated.\n",
            "   - Bob (A): If Bob is an alternator, then his statement about Charlie alternating between truth and lies could be either true or false. However, it doesn't contradict the scenario since we don't know whether Charlie actually alternates or not.\n",
            "   - Charlie (TT): Since Amy lied about Bob being a liar, and her lie implies that Bob is not a liar, it follows that Charlie must be the truth-teller in this scenario.\n",
            "6. A-L-TT:\n",
            "   - Amy (A): Since Amy's statement about Bob being a liar contradicts the fact that Bob is a truth-teller, it must be a lie. This means Bob is not a liar, which implies he is either a truth-teller or an alternator.\n",
            "   - Bob (L): Since Bob is a liar, his statement about Charlie alternating between truth and lies cannot be trusted. However, it doesn't contradict the scenario since we don't know whether Charlie actually alternates or not.\n",
            "   - Charlie (TT): Since Amy lied about Bob being a liar, and her lie implies that Bob is not a liar, it follows that Charlie must be the truth-teller in this scenario.\n",
            "\n",
            "Eliminate Inconsistent Scenarios:\n",
            "1. L-TT-A: Eliminated because Amy's statement contradicts Bob being a truth-teller.\n",
            "2. A-L-TT: Remains consistent.\n",
            "3. TT-A-L: Remains consistent.\n",
            "4. L-A-TT: Eliminated because Charlie must be the truth-teller, which contradicts Amy's statement about Bob being a liar.\n",
            "5. A-L-TT: Remains consistent.\n",
            "6. A-L-TT: Remains consistent.\n",
            "\n",
            "Before concluding \"no solution\":\n",
            "- Re-checked that every scenario was fully explored.\n",
            "- For roles with multiple possible behaviors, confirmed that all possibilities were tested for each affected character/element.\n",
            "\n",
            "Conclude the Solution:\n",
            "- The nature of Amy is an alternator (A), Bob is a truth-teller (TT), and Charlie is also a truth-teller (TT).\n",
            "\n",
            "Provide a Clear Answer:\n",
            "- Amy is an alternator, Bob is a truth-teller, and Charlie is a truth-teller. The only consistent scenario is A-TT-TT, where 'A' stands for the alternator role, 'TT' stands for the truth-teller role. This solution is consistent because it satisfies all given constraints and does not lead to any contradictions when tested against each character's statement.\n"
          ]
        }
      ],
      "source": [
        "# Improved logical reasoning prompt (generic template)\n",
        "\n",
        "logical_reasoning_prompt_v2 = PromptTemplate(\n",
        "    input_variables=[\"scenario\"],\n",
        "    template=\"\"\"Analyze the following logical puzzle thoroughly. Follow these steps in your analysis:\n",
        "\n",
        "List the Facts:\n",
        "- Summarize all the given information and statements clearly.\n",
        "- Identify all the characters or elements involved.\n",
        "- Note exactly how many contributions (statements, actions, data points) each character or element provides in the puzzle. Do not assume or infer additional contributions beyond what is explicitly given.\n",
        "\n",
        "Identify Possible Roles or Conditions:\n",
        "- Determine all possible roles, behaviors, or states applicable to the characters or elements.\n",
        "- For roles or conditions where a character/element can behave in multiple ways (depending on order, state, or context), note that you cannot assume which behavior applies from the given information alone.\n",
        "\n",
        "Note the Constraints:\n",
        "- Outline any rules, constraints, or relationships specified in the puzzle.\n",
        "\n",
        "Generate Possible Scenarios:\n",
        "- Before generating, re-read the constraints. Each scenario MUST satisfy them (e.g., if a unique distribution of roles is specified, every scenario must assign roles accordingly).\n",
        "- List ONLY permutations that satisfy the stated constraints. Do not generate scenarios that violate them (e.g., assigning the same role to multiple characters/elements when the puzzle specifies distinct roles for each).\n",
        "- Systematically consider all valid combinations. Ensure that all permutations are accounted for and that none duplicate roles in violation of constraints.\n",
        "\n",
        "Test Each Scenario:\n",
        "For each permutation of roles/conditions assigned to characters/elements:\n",
        "1. For each character/element, apply the assigned role or condition.\n",
        "2. For roles with a single fixed behavior: the contribution must match that behavior. Do not treat contributions as ambiguous — evaluate whether each contribution is consistent with the assigned role's requirement. If the role implies a specific outcome for the contribution, the contribution must satisfy it; otherwise the scenario is inconsistent.\n",
        "3. For roles with multiple possible behaviors: test EACH possibility separately. Only eliminate the scenario if ALL possibilities lead to contradictions.\n",
        "4. For each character/element, explicitly check: (a) what their contribution implies given the facts, (b) what their role requires of that contribution, (c) whether these match. A mismatch means the scenario is inconsistent.\n",
        "5. Ensure no contradictions between assigned roles and what the contributions imply.\n",
        "\n",
        "Eliminate Inconsistent Scenarios:\n",
        "- IMPORTANT: Evaluate and think thoroughly about ALL scenarios, not just a few!\n",
        "- Discard a scenario only when ALL tested alternatives lead to contradictions.\n",
        "- For scenarios involving roles with multiple possible behaviors, a scenario is consistent if at least one possibility yields no contradictions.\n",
        "- Keep track of the reasoning for eliminating each scenario.\n",
        "\n",
        "Before concluding \"no solution\":\n",
        "- Re-check that every scenario was fully explored.\n",
        "- For roles with multiple possible behaviors, confirm that all possibilities were tested for each affected character/element.\n",
        "\n",
        "Conclude the Solution:\n",
        "- Identify the scenario(s) that remain consistent after testing.\n",
        "- Each scenario shall contain the character or element and its role or condition.\n",
        "- Summarize the findings. Ensure any scenario identifier or shorthand matches the actual role assignment (do not use labels that imply a different distribution than what you are describing).\n",
        "\n",
        "Before providing the final answer:\n",
        "- Verify that your solution satisfies ALL constraints from the puzzle. If the puzzle specifies a unique distribution of roles or conditions, confirm your answer assigns exactly one character/element to each role.\n",
        "\n",
        "Provide a Clear Answer:\n",
        "- State definitively the role or condition of each character or element. The final answer MUST match the consistent scenario(s) you identified.\n",
        "- List each character/element and their role explicitly.\n",
        "- Explain why this is the only possible solution based on your analysis.\n",
        "\n",
        "Scenario:\n",
        "\n",
        "{scenario}\n",
        "\n",
        "Analysis:\"\"\")\n",
        "\n",
        "logical_reasoning_chain_v2 = logical_reasoning_prompt_v2 | llm\n",
        "\n",
        "logical_reasoning_response_v2 = logical_reasoning_chain_v2.invoke(logical_puzzle).content\n",
        "print(logical_reasoning_response_v2)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
